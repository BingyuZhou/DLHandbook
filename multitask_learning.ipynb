{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multitask learning\n",
    "\n",
    "Hydranet in Tesla is a multitask learning example. It is extremely hard to train the beast and let multiple teams to work in the same large network.\n",
    "\n",
    "As a subset of the beast network, prediction and behavior are naturally to be trained together, since many of self driving engineers (including me) believes these two tasks are deeply corelated and can be solved more efficiently when jointly modeling them. The general concept is to encode the environment by some backbone network (e.g. resnet or densenet) and then have multiple heads for prediction and decision tasks.\n",
    "\n",
    "This ends up with the so-called hard sharing network.\n",
    "\n",
    "![](../assets/multitask/multitask.png)\n",
    "\n",
    "This network is difficult to train well due to:\n",
    "\n",
    "1. There are bunch of heads to be either classification or regression tasks. Some are easier, some are harder. Balance of training resource is critical to reach better minimal.\n",
    "2. The dataset can be in different scale and noise level for each task.\n",
    "3. In practice, usually the baseline is the single task network. It means you can have a good baseline of prediction or decision task. However, you can not simply freeze the baseline as the main network and train the another task as a head. Because sometimes the input domain are not exactly the same. For example, route info is needed in decision task, but it is not required in prediction task. A workaround is to add the route info after the backbone and encode it again in cnn. This is not the elegant solution.\n",
    "\n",
    "The 1st problem usually is tackled from loss design and gradient design. The oversample of small number dataset can push some task's train dataset into the same scale as others.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Weighted sum of loss\n",
    "\n",
    "The naive one is:\n",
    "$$\n",
    "Loss = \\sum w L\n",
    "$$\n",
    "$w$ of each task is manully setted by engineer. Usually the weight is selected to scale each task loss to the same level."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Uncertainty aware loss](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kendall_Multi-Task_Learning_Using_CVPR_2018_paper.pdf)\n",
    "\n",
    "This loss design makes the weight of each loss term as an optimization variable. For each of the task, there is a variance learning weight. The final loss is:\n",
    "\n",
    "$$\n",
    "Loss = \\sum_i \\frac{L_i}{\\sigma_i^2} + log \\prod\\sigma_i^2\n",
    "$$\n",
    "\n",
    "The variance term belongs to [homoscedastic uncertianty](https://en.wikipedia.org/wiki/Homoscedasticity), which is aleatoric uncertianty (statistical uncertainty). This uncertainty is constant for different input data, but varies with different tasks.\n",
    "\n",
    "When the task has high uncertainty, its loss will be degraded. Thus, the model will learn the low-uncertain tasks first."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LossUnc(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.log_vars = []\n",
    "        self.task_name = [\"task1\", \"task2\"]\n",
    "        self.t1_loss = nn.CrossEntropyLoss()\n",
    "        self.t2_loss = nn.MSELoss()\n",
    "\n",
    "        for t in self.task_name:\n",
    "            self.log_vars.append(nn.Parameter(torch.zeros(1), requires_grad=True))\n",
    "            self.register_parameter(t, self.log_vars[-1])\n",
    "\n",
    "    def forward(self, t1_pred, t2_pred, t1_y, t2_y):\n",
    "        t1_loss = self.t1_loss(t1_pred, t1_y)\n",
    "        t2_loss = self.t2_loss(t2_pred ,t2_y)\n",
    "\n",
    "        total_loss = 0\n",
    "        for log_var, loss in zip(self.log_vars, [t1_loss, t2_loss]):\n",
    "            w = torch.exp(log_var)\n",
    "            total_loss += (1.0 / w)*loss + log_var\n",
    "        return total_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [Dynamic task prioritization](https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf)\n",
    "\n",
    "For each task, there is a kpi to track how good this task has learned so far. For example, for classification tasks, the kpi ($k_i$) can be the accuracy; for trajectory prediction tasks, the kpi can be the top1 hit rate. Kpi must be in range [0,1], where 1 means perfect learning. The intuition is that the model should learn the difficult tasks first. In another word, tasks with low kpi should be learned with more efforts. Focal loss like term is used to reflect this idea:\n",
    "\n",
    "$$\n",
    "k_i = \\alpha k_{i-1} + (1-\\alpha) k_i \\\\\n",
    "w_i = -(1-k_i)^\\gamma k_i \\\\\n",
    "Loss = \\sum w_i L_i\n",
    "$$\n",
    "\n",
    "- kpi has to be calculated in each iteration, and updated in the moving average fashion for smoothness.\n",
    "- kpi usually doesn't need to be learnable parameters.\n",
    "- for distributed learning, kpi calculation can be in local gpu without distribution communication (`torch.all_reduce()`).\n",
    "- in the focal-loss like weight calculation, increasing $\\gamma$ if we want to focus more on hard negative samples."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def focal_loss(kpi, gamma=1):\n",
    "    return -(1.0-kpi)**gamma*torch.log(kpi+1e-8)\n",
    "\n",
    "class LossDTP(nn.Module):\n",
    "    def __init__(self):\n",
    "        self.log_vars = []\n",
    "        self.task_name = [\"task1\", \"task2\"]\n",
    "        self.t1_loss = nn.CrossEntropyLoss()\n",
    "        self.t2_loss = nn.MSELoss()\n",
    "\n",
    "        self.kpis= [0.0 for _ in self.task_name]\n",
    "        self.alpha = 0.5\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def metric(self, pred, gt):\n",
    "        pass\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_kpi(self, t1_pred, t2_pred, t1_y, t2_y):\n",
    "        kpi1 = self.metric1(t1_pred, t1_y)\n",
    "        kpi2 = self.metric2(t2_pred, t2_y)\n",
    "\n",
    "        for i, cur_kpi in enumerate([kpi1, kpi2]):\n",
    "            self.kpis[i] = self.alpha*cur_kpi+(1-self.alpha)*self.kpis[i]\n",
    "\n",
    "    def forward(self, t1_pred, t2_pred, t1_y, t2_y):\n",
    "        t1_loss = self.t1_loss(t1_pred, t1_y)\n",
    "        t2_loss = self.t2_loss(t2_pred ,t2_y)\n",
    "\n",
    "        self.update_kpi(t1_pred, t2_pred, t1_y, t2_y)\n",
    "\n",
    "        total_loss = 0\n",
    "        for kpi, loss in zip(self.kpis, [t1_loss, t2_loss]):\n",
    "            w = focal_loss(kpi, 1)\n",
    "            total_loss += w*loss\n",
    "        return total_loss"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Summary\n",
    "\n",
    "In practice, hand-picked fixed weights performs better than the uncertainty aware method. DTS is worth to try for multiple tasks."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "968ab3eeb915af72db7aacf10deaadc03d3b360e8f9cd2458aa8925b160b4c7c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}